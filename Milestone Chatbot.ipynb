{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2d3b88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import inflect\n",
    "from nltk import word_tokenize\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf6eff33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt (User Question)</th>\n",
       "      <th>completion (Bot Answer)</th>\n",
       "      <th>persona</th>\n",
       "      <th>pain_point</th>\n",
       "      <th>intent</th>\n",
       "      <th>suggested_usp</th>\n",
       "      <th>CTA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>\"Hi, I need a contractor for our new corporate...</td>\n",
       "      <td>\"We are structured precisely for this requirem...</td>\n",
       "      <td>B2B_Ops_Manager</td>\n",
       "      <td>Risk_Compliance</td>\n",
       "      <td>Verify_Credentials</td>\n",
       "      <td>USP_Certified_Certainty</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>\"I'm a CEO. I don't just want an office; I nee...</td>\n",
       "      <td>\"We share that philosophy. We act as a strateg...</td>\n",
       "      <td>B2B_CEO_Leader</td>\n",
       "      <td>Brand_Alignment</td>\n",
       "      <td>Verify_Capability</td>\n",
       "      <td>USP_Brand_Translation</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>\"I'm an architect, and I'm tired of contractor...</td>\n",
       "      <td>\"We position ourselves as the 'trusted executo...</td>\n",
       "      <td>B2B_Architect</td>\n",
       "      <td>Design_Compromise</td>\n",
       "      <td>Understand_Process</td>\n",
       "      <td>USP_Trusted_Executor</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>\"I need my villa finished perfectly, but I'm a...</td>\n",
       "      <td>\"Absolutely. We provide the luxury of complete...</td>\n",
       "      <td>B2C_Executive</td>\n",
       "      <td>Time_Stress</td>\n",
       "      <td>Verify_Service_Scope</td>\n",
       "      <td>USP_Peace_of_Mind</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>\"My design for my apartment is very complex an...</td>\n",
       "      <td>\"We thrive on that challenge. We act as master...</td>\n",
       "      <td>B2C_Visionary</td>\n",
       "      <td>Technical_Feasibility</td>\n",
       "      <td>Verify_Capability</td>\n",
       "      <td>USP_Master_Craftsman</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                prompt (User Question)  \\\n",
       "1.0  \"Hi, I need a contractor for our new corporate...   \n",
       "2.0  \"I'm a CEO. I don't just want an office; I nee...   \n",
       "3.0  \"I'm an architect, and I'm tired of contractor...   \n",
       "4.0  \"I need my villa finished perfectly, but I'm a...   \n",
       "5.0  \"My design for my apartment is very complex an...   \n",
       "\n",
       "                               completion (Bot Answer)          persona  \\\n",
       "1.0  \"We are structured precisely for this requirem...  B2B_Ops_Manager   \n",
       "2.0  \"We share that philosophy. We act as a strateg...   B2B_CEO_Leader   \n",
       "3.0  \"We position ourselves as the 'trusted executo...    B2B_Architect   \n",
       "4.0  \"Absolutely. We provide the luxury of complete...    B2C_Executive   \n",
       "5.0  \"We thrive on that challenge. We act as master...    B2C_Visionary   \n",
       "\n",
       "                pain_point                intent            suggested_usp  CTA  \n",
       "1.0        Risk_Compliance    Verify_Credentials  USP_Certified_Certainty  NaN  \n",
       "2.0        Brand_Alignment     Verify_Capability    USP_Brand_Translation  NaN  \n",
       "3.0      Design_Compromise    Understand_Process     USP_Trusted_Executor  NaN  \n",
       "4.0            Time_Stress  Verify_Service_Scope        USP_Peace_of_Mind  NaN  \n",
       "5.0  Technical_Feasibility     Verify_Capability     USP_Master_Craftsman  NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read file\n",
    "\n",
    "filename = 'Milestone QA Dataset.csv'\n",
    "df = pd.read_csv(filename, index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4907da",
   "metadata": {},
   "source": [
    "### Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97e95b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt (User Question)</th>\n",
       "      <th>completion (Bot Answer)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Hi, I need a contractor for our new corporate...</td>\n",
       "      <td>\"We are structured precisely for this requirem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"I'm a CEO. I don't just want an office; I nee...</td>\n",
       "      <td>\"We share that philosophy. We act as a strateg...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              prompt (User Question)  \\\n",
       "0  \"Hi, I need a contractor for our new corporate...   \n",
       "1  \"I'm a CEO. I don't just want an office; I nee...   \n",
       "\n",
       "                             completion (Bot Answer)  \n",
       "0  \"We are structured precisely for this requirem...  \n",
       "1  \"We share that philosophy. We act as a strateg...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select columns of interest only\n",
    "df2 = df[['prompt (User Question)', 'completion (Bot Answer)']]\n",
    "\n",
    "# drop index\n",
    "df2.reset_index(drop=True, inplace=True)\n",
    "df2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1a8136a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Hi, I need a contractor for our new corporate...</td>\n",
       "      <td>\"We are structured precisely for this requirem...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  \"Hi, I need a contractor for our new corporate...   \n",
       "\n",
       "                                              answer  \n",
       "0  \"We are structured precisely for this requirem...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rename columns for easier access\n",
    "\n",
    "df3 = df2.rename(columns={'prompt (User Question)':'prompt', 'completion (Bot Answer)':'answer'})\n",
    "df3.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "964ce34c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prompt    0\n",
       "answer    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "df3.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbcc6eda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for duplicates\n",
    "df3.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b36131c",
   "metadata": {},
   "source": [
    "No missing or duplicated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd95a9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Hi, I need a contractor for our new corporate HQ. Our main concern is that our global board requires full compliance with international safety and quality standards. How do you handle this?\"\n",
      "--------------------\n",
      "\"We are structured precisely for this requirement. Our entire management system is audited and certified by Bureau Veritas to be in accordance with ISO 9001 (Quality), ISO 14001 (Environment), and ISO 45001 (Health & Safety)1. This provides 'certified certainty' and ensures our processes are fully compliant from day one.\"\n"
     ]
    }
   ],
   "source": [
    "# Check the text content of first row\n",
    "\n",
    "print(df3.iloc[0,0])\n",
    "print('--------------------')\n",
    "print(df3.iloc[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a9123b",
   "metadata": {},
   "source": [
    "The text seems to contain un-needed quotes in the begging and end of each entry. We need to remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46ece307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi, I need a contractor for our new corporate ...</td>\n",
       "      <td>We are structured precisely for this requireme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm a CEO. I don't just want an office; I need...</td>\n",
       "      <td>We share that philosophy. We act as a strategi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm an architect, and I'm tired of contractors...</td>\n",
       "      <td>We position ourselves as the 'trusted executor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I need my villa finished perfectly, but I'm an...</td>\n",
       "      <td>Absolutely. We provide the luxury of complete ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My design for my apartment is very complex and...</td>\n",
       "      <td>We thrive on that challenge. We act as master ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  Hi, I need a contractor for our new corporate ...   \n",
       "1  I'm a CEO. I don't just want an office; I need...   \n",
       "2  I'm an architect, and I'm tired of contractors...   \n",
       "3  I need my villa finished perfectly, but I'm an...   \n",
       "4  My design for my apartment is very complex and...   \n",
       "\n",
       "                                              answer  \n",
       "0  We are structured precisely for this requireme...  \n",
       "1  We share that philosophy. We act as a strategi...  \n",
       "2  We position ourselves as the 'trusted executor...  \n",
       "3  Absolutely. We provide the luxury of complete ...  \n",
       "4  We thrive on that challenge. We act as master ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3['prompt'] = df3['prompt'].apply(lambda x: x.strip('\"'))\n",
    "df3['answer'] = df3['answer'].apply(lambda x: x.strip('\"'))\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498b64b5",
   "metadata": {},
   "source": [
    "### Text Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1848cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = inflect.engine()\n",
    "\n",
    "def convert_number(text):\n",
    "    temp_str = text.split()\n",
    "    new_string = []\n",
    " \n",
    "    for word in temp_str:\n",
    "        if word.isdigit():\n",
    "            temp = p.number_to_words(word)\n",
    "            new_string.append(temp)\n",
    "        else:\n",
    "            new_string.append(word)\n",
    " \n",
    "    temp_str = ' '.join(new_string)\n",
    "    return temp_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7a9070a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_processing(text):\n",
    "    text1=text.lower() # convert text to lower case\n",
    "    text2 = re.sub(r'https?:\\/\\/\\S+', '', text1) # removes url\n",
    "    clean = re.compile('<.*?>') \n",
    "    text3 = re.sub(clean, '', text2) # remove HTML tags\n",
    "    text4 = re.sub(r\"\\s+\",\" \", text3, flags = re.I) # replace whitespace characters with a single space\n",
    "    text5 = re.sub(r'([\\)\\'\"])\\d+([\\.,]?)', r'\\1\\2', text4)\n",
    "\n",
    "    return text5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fa86626e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'text or will check, and. trys 1 and 2 and &@*#($&^!%) and again queue and too or to html'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's test the function:\n",
    "\n",
    "some_text='text OR WiLL CHECK, and. Trys 1 and 2 and &@*#($&^!%) and http://www.aaa.com again queue and too or to html<and>'\n",
    "text_processing(some_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2f0e5dc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi, I need a contractor for our new corporate ...</td>\n",
       "      <td>We are structured precisely for this requireme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm a CEO. I don't just want an office; I need...</td>\n",
       "      <td>We share that philosophy. We act as a strategi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm an architect, and I'm tired of contractors...</td>\n",
       "      <td>We position ourselves as the 'trusted executor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I need my villa finished perfectly, but I'm an...</td>\n",
       "      <td>Absolutely. We provide the luxury of complete ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My design for my apartment is very complex and...</td>\n",
       "      <td>We thrive on that challenge. We act as master ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  Hi, I need a contractor for our new corporate ...   \n",
       "1  I'm a CEO. I don't just want an office; I need...   \n",
       "2  I'm an architect, and I'm tired of contractors...   \n",
       "3  I need my villa finished perfectly, but I'm an...   \n",
       "4  My design for my apartment is very complex and...   \n",
       "\n",
       "                                              answer  \n",
       "0  We are structured precisely for this requireme...  \n",
       "1  We share that philosophy. We act as a strategi...  \n",
       "2  We position ourselves as the 'trusted executor...  \n",
       "3  Absolutely. We provide the luxury of complete ...  \n",
       "4  We thrive on that challenge. We act as master ...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a1bcd5ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hi, i need a contractor for our new corporate ...</td>\n",
       "      <td>we are structured precisely for this requireme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i'm a ceo. i don't just want an office; i need...</td>\n",
       "      <td>we share that philosophy. we act as a strategi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i'm an architect, and i'm tired of contractors...</td>\n",
       "      <td>we position ourselves as the 'trusted executor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i need my villa finished perfectly, but i'm an...</td>\n",
       "      <td>absolutely. we provide the luxury of complete ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>my design for my apartment is very complex and...</td>\n",
       "      <td>we thrive on that challenge. we act as master ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  hi, i need a contractor for our new corporate ...   \n",
       "1  i'm a ceo. i don't just want an office; i need...   \n",
       "2  i'm an architect, and i'm tired of contractors...   \n",
       "3  i need my villa finished perfectly, but i'm an...   \n",
       "4  my design for my apartment is very complex and...   \n",
       "\n",
       "                                              answer  \n",
       "0  we are structured precisely for this requireme...  \n",
       "1  we share that philosophy. we act as a strategi...  \n",
       "2  we position ourselves as the 'trusted executor...  \n",
       "3  absolutely. we provide the luxury of complete ...  \n",
       "4  we thrive on that challenge. we act as master ...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's apply the function on our data\n",
    "\n",
    "df4 = df3.copy()\n",
    "df4['prompt'] = df3['prompt'].apply(lambda x: text_processing(x))\n",
    "df4['answer'] = df3['answer'].apply(lambda x: text_processing(x))\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "823b28ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are structured precisely for this requirement. Our entire management system is audited and certified by Bureau Veritas to be in accordance with ISO 9001 (Quality), ISO 14001 (Environment), and ISO 45001 (Health & Safety)1. This provides 'certified certainty' and ensures our processes are fully compliant from day one.\n",
      "----------------\n",
      "we are structured precisely for this requirement. our entire management system is audited and certified by bureau veritas to be in accordance with iso 9001 (quality), iso 14001 (environment), and iso 45001 (health & safety). this provides 'certified certainty' and ensures our processes are fully compliant from day one.\n"
     ]
    }
   ],
   "source": [
    "print(df3.iloc[0,1])\n",
    "print('----------------')\n",
    "print(df4.iloc[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d6b552",
   "metadata": {},
   "source": [
    "Now let's prepare the dataset for training using a hugging face model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a4b7c5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch transformers datasets scikit-learn evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bc71ad4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install hf_xet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "125a87ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the data to a hugging face object\n",
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "raw_dataset = Dataset.from_pandas(df4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6cbcfb",
   "metadata": {},
   "source": [
    "We will use GPT-2 pre-trained model. Let's use its tokenizer (AutoTokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9cbeea87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda2\\lib\\site-packages\\huggingface_hub\\file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca9a8b60759944a49fea0283b85e9dfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda2\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Nisma\\.cache\\huggingface\\hub\\models--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42611975953c407680dad6dd240d8505",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5c95c910fba4ce9a001340624c76991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbc1aae06d43483e9fb298292aa7d3b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b91c00340b4a423ba6d0dc45b413a3bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, DataCollatorForLanguageModeling\n",
    "\n",
    "model_name = 'gpt2'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fec129fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dcef4f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the padding token to end of sentence\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1c0a3187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the data collator\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818bee24",
   "metadata": {},
   "source": [
    "Let's prepare our text by formatting the input pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bbdd3854",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(df):\n",
    "    # Join the conversational turn into a single sequence for the model\n",
    "    # Format: User_Prompt + <|endoftext|> + Chatbot_Response + <|endoftext|>\n",
    "    # <|endoftext|> is GPT-2's EOS token and acts as a separator/padding token here.\n",
    "    \n",
    "    # We will assume your dataset has 'input_text' and 'target_text' columns\n",
    "    concatenated_text = [\n",
    "        f\"{prompt} {tokenizer.eos_token} {response} {tokenizer.eos_token}\"\n",
    "        for prompt, response in zip(df['prompt'], df['answer'])\n",
    "    ]\n",
    "\n",
    "    return tokenizer(\n",
    "        concatenated_text, \n",
    "        truncation=True, \n",
    "        max_length=512 # Adjust based on your dataset and VRAM\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ba16091a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c16ddc001439443583cd30a74ccb8423",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/890 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# apply the tokenization to the data\n",
    "\n",
    "tokenized_dataset = raw_dataset.map(tokenize_function, batched=True, remove_columns=raw_dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "be359b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [72, 1101, 257, 2906, 78, 13, 1312, 836, 470, 655, 765, 281, 2607, 26, 1312, 761, 257, 2272, 326, 12497, 674, 1664, 338, 29063, 290, 4508, 5369, 13, 460, 345, 5203, 319, 257, 1029, 12, 5715, 5761, 30, 220, 50256, 356, 2648, 326, 8876, 13, 356, 719, 355, 257, 10039, 5212, 284, 15772, 534, 4508, 338, 5369, 656, 257, 3518, 2858, 17, 13, 674, 15320, 3407, 20533, 6355, 4493, 329, 7534, 588, 1976, 538, 353, 3230, 290, 3958, 4188, 2984, 81, 18, 11, 810, 262, 3061, 373, 10582, 326, 25, 284, 1382, 511, 4508, 338, 29063, 656, 262, 2272, 13, 220, 50256], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_dataset[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "726ee786",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_test_split = tokenized_datasets.train_test_split(test_size=0.2, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9ec62ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetDict\n",
    "\n",
    "final_tokenized_datasets = DatasetDict({'train': train_test_split['train'],'validation': train_test_split['test']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7cf1b15c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "FP16 Mixed precision training with AMP or APEX (`--fp16`) and FP16 half precision evaluation (`--fp16_full_eval`) can only be used on CUDA devices.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[85], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TrainingArguments, Trainer\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# --- 2.1 Define Training Arguments ---\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m training_args \u001b[38;5;241m=\u001b[39m \u001b[43mTrainingArguments\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./gpt2_chatbot_results\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Directory to save logs and checkpoints\u001b[39;49;00m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_train_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                   \u001b[49m\u001b[38;5;66;43;03m# Number of training epochs (adjust as needed)\u001b[39;49;00m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mper_device_train_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Adjust based on your GPU VRAM\u001b[39;49;00m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mper_device_eval_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwarmup_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                     \u001b[49m\u001b[38;5;66;43;03m# Number of steps for learning rate warmup\u001b[39;49;00m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5e-5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                   \u001b[49m\u001b[38;5;66;43;03m# Standard learning rate for fine-tuning\u001b[39;49;00m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogging_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./logs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogging_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevaluation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mepoch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;66;43;03m# Evaluate at the end of each epoch\u001b[39;49;00m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mepoch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# Save model checkpoint at the end of each epoch\u001b[39;49;00m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_best_model_at_end\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;66;43;03m# Load the model with the best validation loss\u001b[39;49;00m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfp16\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m                            \u001b[49m\u001b[38;5;66;43;03m# Enable mixed precision training (if you have a compatible GPU)\u001b[39;49;00m\n\u001b[0;32m     18\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# --- 2.2 Initialize the Trainer ---\u001b[39;00m\n\u001b[0;32m     21\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m     22\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m     23\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m     data_collator\u001b[38;5;241m=\u001b[39mdata_collator,\n\u001b[0;32m     27\u001b[0m )\n",
      "File \u001b[1;32m<string>:104\u001b[0m, in \u001b[0;36m__init__\u001b[1;34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, evaluation_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, eval_delay, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, logging_nan_inf_filter, save_strategy, save_steps, save_total_limit, save_on_each_node, no_cuda, use_mps_device, seed, data_seed, jit_mode_eval, use_ipex, bf16, fp16, fp16_opt_level, half_precision_backend, bf16_full_eval, fp16_full_eval, tf32, local_rank, xpu_backend, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, sharded_ddp, fsdp, fsdp_min_num_params, fsdp_transformer_layer_cls_to_wrap, deepspeed, label_smoothing_factor, optim, adafactor, group_by_length, length_column_name, report_to, ddp_find_unused_parameters, ddp_bucket_cap_mb, dataloader_pin_memory, skip_memory_metrics, use_legacy_prediction_loop, push_to_hub, resume_from_checkpoint, hub_model_id, hub_strategy, hub_token, hub_private_repo, gradient_checkpointing, include_inputs_for_metrics, fp16_backend, push_to_hub_model_id, push_to_hub_organization, push_to_hub_token, mp_parameters, auto_find_batch_size, full_determinism, torchdynamo, ray_scope, ddp_timeout)\u001b[0m\n",
      "File \u001b[1;32mD:\\Anaconda2\\lib\\site-packages\\transformers\\training_args.py:1122\u001b[0m, in \u001b[0;36mTrainingArguments.__post_init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1113\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim \u001b[38;5;241m=\u001b[39m OptimizerNames\u001b[38;5;241m.\u001b[39mADAFACTOR\n\u001b[0;32m   1115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1116\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1117\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m is_torch_available()\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp16 \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp16_full_eval)\n\u001b[0;32m   1121\u001b[0m ):\n\u001b[1;32m-> 1122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1123\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFP16 Mixed precision training with AMP or APEX (`--fp16`) and FP16 half precision evaluation\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1124\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (`--fp16_full_eval`) can only be used on CUDA devices.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1125\u001b[0m     )\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1128\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1129\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m is_torch_available()\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbf16 \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbf16_full_eval)\n\u001b[0;32m   1134\u001b[0m ):\n\u001b[0;32m   1135\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBF16 Mixed precision training with AMP (`--bf16`) and BF16 half precision evaluation\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1137\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (`--bf16_full_eval`) can only be used on CUDA or CPU devices.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1138\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: FP16 Mixed precision training with AMP or APEX (`--fp16`) and FP16 half precision evaluation (`--fp16_full_eval`) can only be used on CUDA devices."
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "# --- 2.1 Define Training Arguments ---\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./gpt2_chatbot_results\",  # Directory to save logs and checkpoints\n",
    "    num_train_epochs=3,                   # Number of training epochs (adjust as needed)\n",
    "    per_device_train_batch_size=4,        # Adjust based on your GPU VRAM\n",
    "    per_device_eval_batch_size=4,\n",
    "    warmup_steps=500,                     # Number of steps for learning rate warmup\n",
    "    learning_rate=5e-5,                   # Standard learning rate for fine-tuning\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=100,\n",
    "    evaluation_strategy=\"epoch\",          # Evaluate at the end of each epoch\n",
    "    save_strategy=\"epoch\",                # Save model checkpoint at the end of each epoch\n",
    "    load_best_model_at_end=True,          # Load the model with the best validation loss\n",
    "    fp16=False,                            # Enable mixed precision training (if you have a compatible GPU)\n",
    ")\n",
    "\n",
    "# --- 2.2 Initialize the Trainer ---\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=final_tokenized_datasets[\"train\"],\n",
    "    eval_dataset=final_tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72055c0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
